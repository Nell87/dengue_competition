rm(p_iquitos, p_sanjuan)
# Remove in data years <= 1999 (validation is from 2008-2013)
# data_sj<- data_sj %>% filter(year %in% c(2000,2001,2002, 2003, 2004, 2005, 2006,
#                                    2007, 2008, 2009, 2010, 2011, 2012, 2013))
#### 2.2. TEMPERATURE IQ & SJ _____________________________________________ ####
# Get the temperature variables
temp_var<-names(data[grep("temp", names(data))])
temp_var_k<-c("temp_air_mean_r","temp_air_avg_r","temp_dewpoint_r","temp_max_r",
"temp_min_r")
# Change everything to celsius
data_iq[temp_var_k]<- kelvin.to.celsius(data_iq[temp_var_k], round = 2)
data_sj[temp_var_k]<- kelvin.to.celsius(data_sj[temp_var_k], round = 2)
rm(temp_var_k)
# Temperature variables train & validation
geom.density.function(data=data_iq, variables=c(temp_var[1:10], "source"),
fill="source")
geom.density.function(data=data_sj, variables=c(temp_var[1:10], "source"),
fill="source")
# Plot the progression of the temperature variables
# p_iq<-plotly.line.function(data_iq,variables= c(temp_var[1:10], "total_cases",
#                                           "week_start_date"), x="week_start_date")
#
# datatemp_sj <- data_sj
# datatemp_sj[temp_var]<-datatemp_sj[temp_var]*10
#
# p_sj<-plotly.line.function(datatemp_sj,variables= c(temp_var[1:10], "total_cases",
#                                           "week_start_date"), x="week_start_date")
#
# saveRDS(p_iq, "./report/temp_iq.rds")
# saveRDS(p_sj, "./report/temp_sj.rds")
readRDS("./report/temp_iq.rds")
readRDS("./report/temp_sj.rds")
rm(temp_var)
#### 2.3. HUMIDITY & PRECIP IQ & SJ _______________________________________ ####
# Get the humidity variables
humid_precip_var<-names(data[grep("humid|precip", names(data))])
# humidity variables train & validation
geom.density.function(data=data_iq, variables=c(humid_precip_var, "source"),
fill="source")
geom.density.function(data=data_sj, variables=c(humid_precip_var, "source"),
fill="source")
# Plot the progression of the temperature variables
# p_iq<-plotly.line.function(data_iq,variables= c(humid_precip_var, "total_cases",
#                                           "week_start_date"), x="week_start_date")
#
# p_sj<-plotly.line.function(data_sj,variables= c(humid_precip_var, "total_cases",
#                                           "week_start_date"), x="week_start_date")
#
# saveRDS(p_iq, "./report/humprec_iq.rds")
# saveRDS(p_sj, "./report/humprec_sj.rds")
readRDS("./report/humprec_iq.rds")
readRDS("./report/humprec_sj.rds")
rm(humid_precip_var)
#### 2.4. VEGETATION IQ & SJ ______________________________________________ ####
# Get the vegetation variables
var_veg<-names(data[grep("ndvi", names(data))])
# humidity variables train & validation
geom.density.function(data=data_iq, variables=c(var_veg, "source"),
fill="source")
geom.density.function(data=data_sj, variables=c(var_veg, "source"),
fill="source")
# Plot the progression of the veg variables
# dataveg_iq <- data_iq
# dataveg_sj <- data_sj
# dataveg_iq[var_veg]<-dataveg_iq[var_veg]*100
# dataveg_sj[var_veg]<-dataveg_sj[var_veg]*1000
#
# p_iq<-plotly.line.function(dataveg_iq,variables= c(var_veg, "total_cases",
#                                           "week_start_date"), x="week_start_date")
#
# p_sj<-plotly.line.function(dataveg_sj,variables= c(var_veg, "total_cases",
#                                           "week_start_date"), x="week_start_date")
#
# saveRDS(p_iq, "./report/veg_iq.rds")
# saveRDS(p_sj, "./report/veg_sj.rds")
readRDS("./report/veg_iq.rds")
readRDS("./report/veg_sj.rds")
rm(var_veg)
#### 0.   INCLUDES / PREPARING DATA _______________________________________ ####
#Load Libraries: p_load can install, load,  and update packages
if(require("pacman")=="FALSE"){
install.packages("pacman")
}
pacman::p_load(rstudioapi,dplyr, ggplot2, lubridate, randomForest,caret,
rpart,rpart.plot, gridExtra,plotly,zoo,gdata,tidyr, reshape2,
weathermetrics)
# Setwd (set current wd where is the script, then we move back to the
# general folder)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("..")
rm(current_path)
# Let's read the script with the own functions
source("./script/functions_sara.R")
# reading datasets
data_x <- read.csv("./data/dengue_features_train.csv", stringsAsFactors = F)
data_y<- read.csv("./data/dengue_labels_train.csv", stringsAsFactors = F)
data<- cbind(data_x, total_cases=data_y$total_cases)
validation<- read.csv("./data/dengue_features_test.csv", stringsAsFactors = F)
rm(data_x, data_y)
#### 1.   CLEANING / PREPROCESSING ####
#### 1.1. Transformations _________________________________________________ ####
# Dimensions
dim(data)          # <-  1456 rows    25 columns
dim(validation)     # <-  416  rows    24 columns
# Rename variables
data <- data %>% rename("precip_amt"= "precipitation_amt_mm",
"precip_mm_r"= "reanalysis_sat_precip_amt_mm",
"temp_dewpoint_r"="reanalysis_dew_point_temp_k",
"temp_air_mean_r" = "reanalysis_air_temp_k",
"humid_relative_r" = "reanalysis_relative_humidity_percent",
"humid_specific_r" = "reanalysis_specific_humidity_g_per_kg",
"precip_kgperm2_r" = "reanalysis_precip_amt_kg_per_m2",
"temp_max_r" = "reanalysis_max_air_temp_k",
"temp_min_r" = "reanalysis_min_air_temp_k",
"temp_air_avg_r" = "reanalysis_avg_temp_k",
"temp_dir_range_r" = "reanalysis_tdtr_k",
"temp_max_st"= "station_max_temp_c",
"temp_min_st"= "station_min_temp_c",
"temp_avg_st"= "station_avg_temp_c",
"precip_st" = "station_precip_mm",
"temp_dir_range_st" = "station_diur_temp_rng_c")
# Rename variables
validation <- validation %>% rename("precip_amt"= "precipitation_amt_mm",
"precip_mm_r"= "reanalysis_sat_precip_amt_mm",
"temp_dewpoint_r"="reanalysis_dew_point_temp_k",
"temp_air_mean_r" = "reanalysis_air_temp_k",
"humid_relative_r" = "reanalysis_relative_humidity_percent",
"humid_specific_r" = "reanalysis_specific_humidity_g_per_kg",
"precip_kgperm2_r" = "reanalysis_precip_amt_kg_per_m2",
"temp_max_r" = "reanalysis_max_air_temp_k",
"temp_min_r" = "reanalysis_min_air_temp_k",
"temp_air_avg_r" = "reanalysis_avg_temp_k",
"temp_dir_range_r" = "reanalysis_tdtr_k",
"temp_max_st"= "station_max_temp_c",
"temp_min_st"= "station_min_temp_c",
"temp_avg_st"= "station_avg_temp_c",
"precip_st" = "station_precip_mm",
"temp_dir_range_st" = "station_diur_temp_rng_c")
# Transform some variables to factor/numeric/datetime
data$week_start_date<- ymd(data$week_start_date)
validation$week_start_date<- ymd(validation$week_start_date)
data$city <- as.factor(data$city)
data$year <- year(data$week_start_date)
data$weekofyear<- as.factor(data$weekofyear)
data$month<- month(data$week_start_date)
validation$city <- as.factor(validation$city)
validation$year<- year(validation$week_start_date)
validation$weekofyear <- as.factor(validation$weekofyear)
validation$month<- month(validation$week_start_date)
#### 1.2. Split in two cities _____________________________________________ ####
# Combine datasets for checking distributions data & validation
validation$total_cases<-0
data_full<-gdata::combine(data, validation)
# data_iq<-data %>% filter(city=="iq")
# data_sj<-data %>% filter(city=="sj")
data_iq<-data_full %>% filter(city=="iq")
data_sj<-data_full %>% filter(city=="sj")
#### 1.3. Missing values __________________________________________________ ####
data<-na.locf(data)
validation<-na.locf(validation)
# where and how many missing values
missing_values <- data_sj %>%
filter(year>2000) %>%
select_if(is.numeric) %>%
gather(key = "key", value = "val") %>%
mutate(is.missing = is.na(val)) %>%
group_by(key, is.missing) %>%
summarise(num.missing = n()) %>%
filter(is.missing==T) %>%
select(-is.missing) %>%
arrange(desc(num.missing))
ggplot(missing_values, aes(x=key, y=num.missing, fill=key)) +
geom_bar(stat="identity") +
theme(axis.text.x = element_text(angle=60, hjust=1)) +
ggtitle("Missing values per variable") +
guides(fill = guide_legend(ncol = 2))
data_sj<-na.locf(data_sj)
data_iq<-na.locf(data_iq)
data_full<-rbind(data_sj, data_iq)
rm(missing_values)
write.csv(data_full, "./report/data_full.csv", row.names = FALSE)
# This is an useful funtion to profile and optimize code
# profvis(knitr::knit("C:/SARA/GitHub/dengue_competition/report/dengue_report.Rmd", encoding = 'UTF-8'))
# load Libraries: p_load can install, load,  and update packages
library(dplyr)
library(ggplot2)
library(lubridate)
library(plotly)
library(gdata)
library(weathermetrics)
library(reshape2)
library(tidyr)
library(zoo)
library(formattable)
library(gridExtra)
# reading datasets
data_iq <- read.csv("data_noNA_aftercor_iq.csv", stringsAsFactors = F)
data_sj<- read.csv("data_noNA_aftercor_sj.csv", stringsAsFactors = F)
data_full<-read.csv("data_full.csv", stringsAsFactors=F)
# Transform some variables to factor/numeric/datetime
data_iq$week_start_date<- ymd(data_iq$week_start_date)
data_sj$week_start_date<- ymd(data_sj$week_start_date)
data_iq$city <- as.factor(data_iq$city)
data_sj$city <- as.factor(data_sj$city)
data_iq$year <- year(data_iq$week_start_date)
data_sj$year <- year(data_sj$week_start_date)
data_iq$weekofyear<- as.factor(data_iq$weekofyear)
data_iq$weekofyear<- as.factor(data_iq$weekofyear)
data_iq$month<- month(data_iq$month)
data_sj$month<- month(data_sj$month)
data_iq$source<- as.factor(data_iq$source)
data_sj$source<- as.factor(data_sj$source)
final_variables<-data.frame(Iquitos = names(data_full), San_Juan = names(data_full))
rownames(final_variables)<- names(data_full)
final_variables$Iquitos<-ifelse(final_variables$Iquitos %in% names(data_iq),
"Yes", "Removed")
final_variables$San_Juan<-ifelse(final_variables$San_Juan %in% names(data_sj),
"Yes", "Removed")
# Replacing empty cells with icons
formattable(final_variables, list(
Iquitos = formatter("span", style = x ~ ifelse(x == "Yes",
style(color = "green", font.weight = "bold"), style(color="red",font.weight = "bold"))),
San_Juan = formatter("span", style = x ~ ifelse(x == "Yes",
style(color = "green", font.weight = "bold"), style(color="red",font.weight = "bold")))
))
# Plot the progression of the temperature variables
p<-readRDS("temp_iq.rds")
p
#### 0.   INCLUDES / PREPARING DATA _______________________________________ ####
#Load Libraries: p_load can install, load,  and update packages
if(require("pacman")=="FALSE"){
install.packages("pacman")
}
pacman::p_load(rstudioapi,dplyr, ggplot2, lubridate, randomForest,caret,
rpart,rpart.plot, gridExtra,plotly,zoo,gdata,tidyr, reshape2,
weathermetrics)
# Setwd (set current wd where is the script, then we move back to the
# general folder)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("..")
rm(current_path)
# Let's read the script with the own functions
source("./script/functions_sara.R")
# reading datasets
data_x <- read.csv("./data/dengue_features_train.csv", stringsAsFactors = F)
data_y<- read.csv("./data/dengue_labels_train.csv", stringsAsFactors = F)
data<- cbind(data_x, total_cases=data_y$total_cases)
validation<- read.csv("./data/dengue_features_test.csv", stringsAsFactors = F)
rm(data_x, data_y)
#### 1.   CLEANING / PREPROCESSING ####
#### 1.1. Transformations _________________________________________________ ####
# Dimensions
dim(data)          # <-  1456 rows    25 columns
dim(validation)     # <-  416  rows    24 columns
# Rename variables
data <- data %>% rename("precip_amt"= "precipitation_amt_mm",
"precip_mm_r"= "reanalysis_sat_precip_amt_mm",
"temp_dewpoint_r"="reanalysis_dew_point_temp_k",
"temp_air_mean_r" = "reanalysis_air_temp_k",
"humid_relative_r" = "reanalysis_relative_humidity_percent",
"humid_specific_r" = "reanalysis_specific_humidity_g_per_kg",
"precip_kgperm2_r" = "reanalysis_precip_amt_kg_per_m2",
"temp_max_r" = "reanalysis_max_air_temp_k",
"temp_min_r" = "reanalysis_min_air_temp_k",
"temp_air_avg_r" = "reanalysis_avg_temp_k",
"temp_dir_range_r" = "reanalysis_tdtr_k",
"temp_max_st"= "station_max_temp_c",
"temp_min_st"= "station_min_temp_c",
"temp_avg_st"= "station_avg_temp_c",
"precip_st" = "station_precip_mm",
"temp_dir_range_st" = "station_diur_temp_rng_c")
# Rename variables
validation <- validation %>% rename("precip_amt"= "precipitation_amt_mm",
"precip_mm_r"= "reanalysis_sat_precip_amt_mm",
"temp_dewpoint_r"="reanalysis_dew_point_temp_k",
"temp_air_mean_r" = "reanalysis_air_temp_k",
"humid_relative_r" = "reanalysis_relative_humidity_percent",
"humid_specific_r" = "reanalysis_specific_humidity_g_per_kg",
"precip_kgperm2_r" = "reanalysis_precip_amt_kg_per_m2",
"temp_max_r" = "reanalysis_max_air_temp_k",
"temp_min_r" = "reanalysis_min_air_temp_k",
"temp_air_avg_r" = "reanalysis_avg_temp_k",
"temp_dir_range_r" = "reanalysis_tdtr_k",
"temp_max_st"= "station_max_temp_c",
"temp_min_st"= "station_min_temp_c",
"temp_avg_st"= "station_avg_temp_c",
"precip_st" = "station_precip_mm",
"temp_dir_range_st" = "station_diur_temp_rng_c")
# Transform some variables to factor/numeric/datetime
data$week_start_date<- ymd(data$week_start_date)
validation$week_start_date<- ymd(validation$week_start_date)
data$city <- as.factor(data$city)
data$year <- year(data$week_start_date)
data$weekofyear<- as.factor(data$weekofyear)
data$month<- month(data$week_start_date)
validation$city <- as.factor(validation$city)
validation$year<- year(validation$week_start_date)
validation$weekofyear <- as.factor(validation$weekofyear)
validation$month<- month(validation$week_start_date)
#### 1.2. Split in two cities _____________________________________________ ####
# Combine datasets for checking distributions data & validation
validation$total_cases<-0
data_full<-gdata::combine(data, validation)
# data_iq<-data %>% filter(city=="iq")
# data_sj<-data %>% filter(city=="sj")
data_iq<-data_full %>% filter(city=="iq")
data_sj<-data_full %>% filter(city=="sj")
#### 1.3. Missing values __________________________________________________ ####
data<-na.locf(data)
validation<-na.locf(validation)
# where and how many missing values
missing_values <- data_sj %>%
filter(year>2000) %>%
select_if(is.numeric) %>%
gather(key = "key", value = "val") %>%
mutate(is.missing = is.na(val)) %>%
group_by(key, is.missing) %>%
summarise(num.missing = n()) %>%
filter(is.missing==T) %>%
select(-is.missing) %>%
arrange(desc(num.missing))
ggplot(missing_values, aes(x=key, y=num.missing, fill=key)) +
geom_bar(stat="identity") +
theme(axis.text.x = element_text(angle=60, hjust=1)) +
ggtitle("Missing values per variable") +
guides(fill = guide_legend(ncol = 2))
data_sj<-na.locf(data_sj)
data_iq<-na.locf(data_iq)
data_full<-rbind(data_sj, data_iq)
rm(missing_values)
#### 1.4. Outliers ________________________________________________________ ####
data_iq %>%
select(-city, -year, - weekofyear, -month) %>%
mutate(ndvi_ne=ndvi_ne*1000, ndvi_nw=ndvi_nw*1000,
ndvi_se=ndvi_se*1000, ndvi_sw=ndvi_sw*1000) %>%
melt(c("week_start_date", "source")) %>%
mutate(value=as.numeric(value)) %>%
ggplot() + aes(x=variable, y=value) +
geom_boxplot() + facet_wrap(~source) +
coord_flip()    # We can see a huge difference in the level of precip.
data_iq %>%
select(source,week_start_date, starts_with("precip")) %>%
melt(c("week_start_date", "source")) %>%
ggplot() + aes(x=variable, y=value, fill=source) +
geom_boxplot()
data_iq %>%
select(source,week_start_date, starts_with("precip")) %>%
melt(c("week_start_date", "source")) %>%
group_by(source, variable) %>%
dplyr::summarise(median_var= max(value, na.rm = TRUE))
# data precip st     md 45.3     max 543
# valid precip st    md 27.2     max 212
data_sj %>% filter(source=="data") %>%
select(-city, -year, - weekofyear, -month) %>%
melt("week_start_date") %>%
mutate(value=as.numeric(value)) %>%
ggplot() + aes(x=variable, y=value) +
geom_boxplot() + coord_flip()
#### 2.0  EXPLORATORY ANALYSIS ####
#### 2.1. YEAR __________________________________________________________####
summary(data_iq$year)     # <- 2000 to 2010
summary(data_sj$year)     # <- 1990 to 2010
summary(validation$year)  # <- 2008 to 2013
# Some years have the week mislabeled (first week as 52/53, second week as 1...).
weird_weeks_iq<-data_iq %>% filter(month(data_iq$week_start_date)==1 &
data_iq$weekofyear==1 &
day(data_iq$week_start_date)!=1)
weird_weeks_sj<-data_sj %>% filter(month(data_sj$week_start_date)==1 &
data_sj$weekofyear==1 &
day(data_sj$week_start_date)!=1)
data_iq<- data_iq %>%
mutate(weekofyear=as.numeric(weekofyear)) %>%
mutate(weekofyear=
ifelse (year %in% weird_weeks_iq$year &
month(week_start_date)==1 &
day(week_start_date)==1,1,
ifelse(year %in% weird_weeks_iq$year &
month(week_start_date)==1 &
day(week_start_date)!=1, weekofyear +1, weekofyear)
))
data_sj<- data_sj %>%
mutate(weekofyear=as.numeric(weekofyear)) %>%
mutate(weekofyear=
ifelse (year %in% weird_weeks_sj$year &
month(week_start_date)==1 &
day(week_start_date)==1,1,
ifelse(year %in% weird_weeks_sj$year &
month(week_start_date)==1 &
day(week_start_date)!=1, weekofyear +1, weekofyear)
))
data_full<- rbind(data_iq, data_sj)
rm(weird_weeks_iq, weird_weeks_sj)
# Cases depending on the week of the year ______________________________________
p_iquitos<-ggplot(data_full[data_full$source=="data" & data_full$city=="iq",],
aes(x=weekofyear, y=total_cases, color=factor(year))) +
geom_point() + ggtitle("Total cases per week -Iquitos-") +
guides(colour = guide_legend(ncol = 2))
p_sanjuan<-ggplot(data_full[data_full$source=="data" & data_full$city=="sj",],
aes(x=weekofyear, y=total_cases, color=factor(year))) +
geom_point() + ggtitle("Total cases per week -San Juan-") +
guides(colour = guide_legend(ncol = 2))
grid.arrange(p_iquitos, p_sanjuan, ncol=1)
rm(p_iquitos, p_sanjuan)
# Remove in data years <= 1999 (validation is from 2008-2013)
# data_sj<- data_sj %>% filter(year %in% c(2000,2001,2002, 2003, 2004, 2005, 2006,
#                                    2007, 2008, 2009, 2010, 2011, 2012, 2013))
#### 2.2. TEMPERATURE IQ & SJ _____________________________________________ ####
# Get the temperature variables
temp_var<-names(data[grep("temp", names(data))])
temp_var_k<-c("temp_air_mean_r","temp_air_avg_r","temp_dewpoint_r","temp_max_r",
"temp_min_r")
# Change everything to celsius
data_iq[temp_var_k]<- kelvin.to.celsius(data_iq[temp_var_k], round = 2)
data_sj[temp_var_k]<- kelvin.to.celsius(data_sj[temp_var_k], round = 2)
rm(temp_var_k)
# Temperature variables train & validation
geom.density.function(data=data_iq, variables=c(temp_var[1:10], "source"),
fill="source")
geom.density.function(data=data_sj, variables=c(temp_var[1:10], "source"),
fill="source")
# Plot the progression of the temperature variables
p_iq<-plotly.line.function(data_iq,variables= c(temp_var[1:10], "total_cases",
"week_start_date"), x="week_start_date")
save(p_iq, "./report/p_iq.rda")
save(p_iq, "./report/p_iq.rda")
save("./report/p_iq.rds")
?save
save(p_iq, file = "p_iq.RData")
# Plot the progression of the temperature variables
load("p_iq.RData")
# Plot the progression of the temperature variables
load("p_iq.RData")
# Plot the progression of the temperature variables
load("p_iq.RData")
# Plot the progression of the temperature variables
p<-load("p_iq.RData")
p
plot(p)
?readRDS
# reading datasets
data_iq <- read.csv("data_noNA_aftercor_iq.csv", stringsAsFactors = F)
data_sj<- read.csv("data_noNA_aftercor_sj.csv", stringsAsFactors = F)
data_full<-read.csv("data_full.csv", stringsAsFactors=F)
names(data_full)
data_iq_complete<-data_full %>% filter(city=="iq")
data_sj_complete<-data_full %>% filter(city=="sj")
# Plot the progression of the temperature variables	# Plot the progression of the temperature variables
plotly.line.function(data_iq_complete,variables= c(temp_var[1:10], "total_cases", 	readRDS("temp_iq.rds"),
"week_start_date"), x="week_start_date")
# This is an useful funtion to profile and optimize code
# profvis(knitr::knit("C:/SARA/GitHub/dengue_competition/report/dengue_report.Rmd", encoding = 'UTF-8'))
# load Libraries: p_load can install, load,  and update packages
library(dplyr)
library(ggplot2)
library(lubridate)
library(plotly)
library(gdata)
library(weathermetrics)
library(reshape2)
library(tidyr)
library(zoo)
library(formattable)
library(gridExtra)
# reading datasets
data_iq <- read.csv("data_noNA_aftercor_iq.csv", stringsAsFactors = F)
data_sj<- read.csv("data_noNA_aftercor_sj.csv", stringsAsFactors = F)
data_full<-read.csv("data_full.csv", stringsAsFactors=F)
# Transform some variables to factor/numeric/datetime
data_iq$week_start_date<- ymd(data_iq$week_start_date)
data_sj$week_start_date<- ymd(data_sj$week_start_date)
data_full$week_start_date<- ymd(data_full$week_start_date)
data_iq$city <- as.factor(data_iq$city)
data_sj$city <- as.factor(data_sj$city)
data_full$city <- as.factor(data_full$city)
data_iq$year <- year(data_iq$week_start_date)
data_sj$year <- year(data_sj$week_start_date)
data_full$year <- year(data_full$week_start_date)
data_iq$weekofyear<- as.factor(data_iq$weekofyear)
data_sj$weekofyear<- as.factor(data_sj$weekofyear)
data_full$weekofyear<- as.factor(data_full$weekofyear)
data_iq$month<- month(data_iq$month)
data_sj$month<- month(data_sj$month)
data_full$month<- month(data_full$month)
data_iq$source<- as.factor(data_iq$source)
data_sj$source<- as.factor(data_sj$source)
data_full$source<- as.factor(data_full$source)
data_iq_complete<-data_full %>% filter(city=="iq")
data_sj_complete<-data_full %>% filter(city=="sj")
# FUNCTIONS
# Plotly with lines. Example: datetime and different variables 	data_iq$city <- as.factor(data_iq$city)
# (val and train together)	data_sj$city <- as.factor(data_sj$city)
plotly.line.function <- function(data, variables, x){
# Melt with the selected variables
data<- data[variables] %>%
melt(x) %>%
rename("id"=x)
# plotly line
plot_ly(data, x = ~id, y = ~value,
color = ~variable, type = 'scatter', mode = 'lines')
}
# Plot the progression of the temperature variables	# Plot the progression of the temperature variables
plotly.line.function(data_iq_complete,variables= c(temp_var[1:10], "total_cases", 	readRDS("temp_iq.rds"),
"week_start_date"), x="week_start_date")
# Get the temperature variables	![](dengue_distributions_temp_iq.png){width=700px}
temp_var<-names(data[grep("temp", names(data))])
# Get the temperature variables	![](dengue_distributions_temp_iq.png){width=700px}
temp_var<-names(data_full[grep("temp", names(data_full))])
temp_var
temp_var_k<-c("temp_air_mean_r","temp_air_avg_r","temp_dewpoint_r","temp_max_r",
"temp_min_r")
